# ProjectInspectionSkill Integration Guide

## ğŸš€ Quick Start: 3 Steps to Activate

### Step 1: Verify Installation âœ…

The ProjectInspectionSkill is already implemented and tested:

```bash
# Check implementation
ls -la agent_core/project_inspection.py

# Run acceptance tests
python3 tests/test_project_inspection_acceptance.py

# Run stress tests
python3 tests/test_project_inspection_stress.py
```

**Expected Output**: All tests PASS âœ“

---

### Step 2: Register with Orchestrator

Add to `agent_core/orchestrator.py` or relevant orchestration file:

```python
# At initialization time
from agent_core.project_inspection import ProjectInspectionPipeline

class Orchestrator:
    def __init__(self):
        self.inspection_pipeline = ProjectInspectionPipeline()
        # ... other initialization

    def should_inspect_project(self, user_intent: str) -> bool:
        """Check if user intent suggests project analysis."""
        keywords = ['analyze', 'inspect', 'debug', 'understand', 'structure', 'architecture']
        intent_lower = user_intent.lower()
        return any(keyword in intent_lower for keyword in keywords)

    def generate_debug_plan(self, task: str) -> Plan:
        """Generate debugging plan with inspection phase."""
        plan = Plan()

        # Phase 0: Inspect project
        if self.should_inspect_project(task):
            report = self.inspection_pipeline.run_full_inspection()
            plan.add_metadata('project_report', report)

            # Add approval phase
            plan.add_step(
                name='SHOW_REPORT',
                description='Display project analysis and ask for approval',
                requires_approval=True,
                data=report.to_dict()
            )

            # Add test execution phase
            for i, target in enumerate(report.test_targets, 1):
                plan.add_step(
                    name=f'TEST_{i}',
                    description=target.description,
                    command=target.verification_cmd,
                    risk_level=target.risk_level.value
                )

        # ... rest of plan generation
        return plan
```

---

### Step 3: Display Report in REPL

Add to REPL approval handler:

```python
# In agent_core/interface/repl.py or console output

from agent_core.project_inspection import ProjectInspectionPipeline, RiskLevel
from rich.console import Console
from rich.table import Table
from rich.panel import Panel

def display_inspection_report(report):
    """Display project inspection report with Rich formatting."""
    console = Console()

    # Title
    console.print("\n", style="bold")
    console.print("ğŸ” PROJECT INSPECTION COMPLETE", style="bold cyan")
    console.print()

    # Summary table
    summary_table = Table(title="Project Summary", show_header=False)
    summary_table.add_row("Type", report.project_info.project_type.value)
    summary_table.add_row("Language", report.project_info.language)
    summary_table.add_row("Entry Point", report.project_info.entry_point or "N/A")
    summary_table.add_row("Build Tool", report.project_info.build_tool or "N/A")
    console.print(summary_table)

    # Modules table
    modules_table = Table(title=f"Modules ({len(report.modules)})")
    modules_table.add_column("Module", style="cyan")
    modules_table.add_column("Responsibility")
    modules_table.add_column("Has Tests")

    for module in report.modules:
        has_test = "âœ“" if module.test_file else "âœ—"
        modules_table.add_row(module.name, module.responsibility, has_test)

    console.print(modules_table)

    # Test targets
    targets_table = Table(title=f"Test Targets ({len(report.test_targets)})")
    targets_table.add_column("ID")
    targets_table.add_column("Description")
    targets_table.add_column("Risk", justify="center")
    targets_table.add_column("Command")

    risk_colors = {
        RiskLevel.CRITICAL: "red",
        RiskLevel.HIGH: "red",
        RiskLevel.MEDIUM: "yellow",
        RiskLevel.LOW: "green"
    }

    for target in report.test_targets:
        color = risk_colors.get(target.risk_level, "white")
        targets_table.add_row(
            target.id,
            target.description,
            f"[{color}]{target.risk_level.value}[/{color}]",
            target.verification_cmd
        )

    console.print(targets_table)

    # Recommendations
    console.print(Panel("""
[bold]Recommended Debugging Order:[/bold]

1. Start with [green]LOW[/green] risk tests
2. Move to [yellow]MEDIUM[/yellow] risk tests
3. Address [red]HIGH[/red] and [red]CRITICAL[/red] issues
4. Run full regression suite

[bold]Next Step:[/bold]
Review test targets above and confirm which to execute first?
    """, title="Debug Guide"))

    console.print()
```

---

## ğŸ“Š Example Output

When a user runs: `"å¸®æˆ‘åˆ†æè¿™ä¸ªé¡¹ç›®çš„ç»“æ„"`

```
ğŸ” PROJECT INSPECTION COMPLETE

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Project Summary                  â”ƒ
â”£â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”«
â”ƒ Type        | python_cli         â”ƒ
â”ƒ Language    | Python             â”ƒ
â”ƒ Entry Point | main.py            â”ƒ
â”ƒ Build Tool  | pip                â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Modules (4)                                       â”ƒ
â”£â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”«
â”ƒ Module â”‚ Responsibility      â”‚ Has Tests â”‚        â”ƒ
â”£â”â”â”â”â•‹â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‹â”â”â”â”â”â”â”â”â”â”â”â”â•‹â”â”â”â”â”â”â”â”â”«
â”ƒ main   â”‚ Entry point         â”‚ âœ—         â”‚        â”ƒ
â”ƒ calc   â”‚ Core logic          â”‚ âœ“         â”‚        â”ƒ
â”ƒ utils  â”‚ Utility functions   â”‚ âœ—         â”‚        â”ƒ
â”ƒ test_  â”‚ Unit tests          â”‚ âœ“         â”‚        â”ƒ
â”—â”â”â”â”â”»â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”»â”â”â”â”â”â”â”â”â”â”â”â”â”»â”â”â”â”â”â”â”â”â”›

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Test Targets (3)                                        â”ƒ
â”£â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”«
â”ƒ ID â”‚ Description â”‚ Risk â”‚ Command                 â”ƒ
â”£â”â”â”â•‹â”â”â”â”â”â”â”â”â”â”â”â”â”â•‹â”â”â”â”â”â”â•‹â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”«
â”ƒ T1 â”‚ Test calc   â”‚ LOW  â”‚ python -m pytest test_c â”ƒ
â”ƒ T2 â”‚ Verify main â”‚ MED  â”‚ python -m pytest main_t â”ƒ
â”ƒ T3 â”‚ Verify util â”‚ MED  â”‚ python -m pytest utils_ â”ƒ
â”—â”â”â”â”»â”â”â”â”â”â”â”â”â”â”â”â”â”â”»â”â”â”â”â”â”â”»â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›

Recommended Debugging Order:

1. Start with LOW risk tests
2. Move to MEDIUM risk tests
3. Address HIGH and CRITICAL issues
4. Run full regression suite

Next Step:
Review test targets above and confirm which to execute first?
```

---

## ğŸ”— Integration Checklist

- [ ] Copy `agent_core/project_inspection.py` to your system
- [ ] Add import to `orchestrator.py`
- [ ] Implement `should_inspect_project()` logic
- [ ] Add inspection phase to plan generation
- [ ] Create REPL display function
- [ ] Test with dummy_broken_calculator project
- [ ] Run acceptance tests to verify integration
- [ ] Run stress tests for robustness check
- [ ] Update documentation

---

## ğŸ§ª Testing Integration

### Acceptance Test Verification

```bash
# Run all acceptance tests
python3 tests/test_project_inspection_acceptance.py

# Expected output:
# Total: 4/4 passed âœ“
```

### Stress Test Verification

```bash
# Run extreme stress tests
python3 tests/test_project_inspection_stress.py

# Expected output:
# Total: 3/3 passed âœ“
```

### Manual Test with Demo Project

```bash
# Inspect the broken calculator project
python3 << 'EOF'
from agent_core.project_inspection import ProjectInspectionPipeline
import os

os.chdir('tests/scenarios/dummy_broken_calculator')
pipeline = ProjectInspectionPipeline(project_root='.')
report = pipeline.run_full_inspection()

print(f"âœ“ Found {len(report.modules)} modules")
print(f"âœ“ Generated {len(report.test_targets)} test targets")
print(f"âœ“ Report saved to: {pipeline.save_report('.')}")
EOF
```

---

## ğŸ¯ Success Criteria

âœ… **All Acceptance Tests Pass** (4/4)
âœ… **All Stress Tests Pass** (3/3)
âœ… **Report Generated Correctly**
âœ… **Test Targets Identified**
âœ… **No Crashes on Edge Cases**
âœ… **Integration Ready**

---

## ğŸ“ Support & FAQ

**Q: How do I customize module responsibility inference?**
A: Edit `ProjectInspector._infer_responsibility()` in `project_inspection.py`

**Q: Can I exclude specific directories?**
A: Modify `cache_dirs` list in `analyze_modules()` method

**Q: How do I extend for a new language?**
A: Add detection logic to `scan_structure()` method

**Q: What if my project structure is unusual?**
A: The pipeline provides base functionality; you can subclass and extend

---

## ğŸš€ Next Phase: Integration

Once integrated, Agent OS will automatically:

1. âœ“ Analyze project structure on user request
2. âœ“ Identify modules and responsibilities
3. âœ“ Generate test targets
4. âœ“ Display comprehensive report
5. âœ“ Guide debugging workflow
6. âœ“ Execute tests in recommended order

This transforms Agent OS from exploratory to engineering-grade! ğŸ‰

---

**Ready to integrate?** Start with Step 2 above!
